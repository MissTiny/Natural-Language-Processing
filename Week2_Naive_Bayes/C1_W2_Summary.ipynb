{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09f4921",
   "metadata": {},
   "source": [
    "### Naive Bayes Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf951e",
   "metadata": {},
   "source": [
    "1. Get dataset with labels and preprocessing\n",
    "2. Compute freq(w,class) -- How many times each words appears in the positive corpus & How many times each words appears in the nagetive corpus\n",
    "3. Compute P(w|pos),P(w|neg). $P(w|pos) = \\frac{freq(w,pos)+1}{num\\_of\\_words\\_in\\_pos+unique\\_words\\_in\\_total}$\n",
    "4. Compute $\\lambda = log \\frac{P(w|pos)}{P(w|neg)}$ (This should be a dictionary of words)\n",
    "5. Compute $logprior = log(P(pos)/P(neg))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2baf92",
   "metadata": {},
   "source": [
    "### Bayes Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a83dce",
   "metadata": {},
   "source": [
    "$$P(A|B)=\\frac{P(A \\cap B)}{P(B)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96883b22",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d621513a",
   "metadata": {},
   "source": [
    "1. Create a chart of $P(word|\"positive\")$ and $P(word|\"negative\")$<br>\n",
    "2. Probability of a \"word\" being positive = $P(word)$ = $\\frac{P(word|\"positive\")}{P(word|\"negative\")}$<br>\n",
    "3. The sentiment of a sentence = $\\Pi_{i}^{n}P(word_{i})$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d1979",
   "metadata": {},
   "source": [
    "> if $P(word) > 1$,then the word is more likely to be positive <br>\n",
    "> if $0 < P(word) < 1$,then the word is more likely to be negative <br>\n",
    "> if $P(word)=0$,then the word is neutral <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b405fa0",
   "metadata": {},
   "source": [
    "### Log Likeligood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a29915a",
   "metadata": {},
   "source": [
    "To normalize P(word) and make P(sentence) easier to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a0e36",
   "metadata": {},
   "source": [
    "$$log(\\Pi_{i}^{n}P(word_{i})) = \\Sigma log( P(word_{i}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15f067",
   "metadata": {},
   "source": [
    "With normalize to unbalanced corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05457281",
   "metadata": {},
   "source": [
    "$$log(\\frac{P(positive)}{P(negative)}\\Pi_{i}^{n}P(word_{i})) = log \\frac{P(positive)}{P(negative)} +\\Sigma log( P(word_{i}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf89954",
   "metadata": {},
   "source": [
    "$$\\lambda(w) = log P(word)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
